{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ed702-0cc2-4ff6-9557-ce01a041d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from peft import LoraConfig\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from trl.trainer import ConstantLengthDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca8c64-9985-4ddd-a00a-575914e427eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745df1b-ff70-46b5-b25b-3e9b21d99770",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_path = \"./data/used_car_sales/prepared_car_sales_data\"\n",
    "    # model related\n",
    "    # model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
    "    # run_name = \"deepseekLLM7bBaseFinetuned\"\n",
    "    # model_name = \"openai-community/gpt2-large\"\n",
    "    # run_name = \"gpt2_large\"\n",
    "    model_name = \"stabilityai/stablelm-3b-4e1t\"\n",
    "    run_name = \"stability_stablelm_3b\"\n",
    "\n",
    "    # bitsandbytes params\n",
    "    load_in_4bit = True\n",
    "    bnb_4bit_quant_type = \"nf4\"\n",
    "    bnb_4bit_use_double_quant = False\n",
    "\n",
    "    sequence_length = 512\n",
    "\n",
    "    # Lora params\n",
    "    r = 4  # the rank of the LoRA matrices\n",
    "    lora_alpha = 16  # the weight\n",
    "    lora_dropout = 0.1  # dropout to add to the LoRA layers\n",
    "\n",
    "    # Training Params\n",
    "    output_dir = \"./car_sales_predictor/\"\n",
    "    evaluation_strategy = \"steps\"\n",
    "    max_steps = 1000\n",
    "    num_train_epochs = 1\n",
    "    save_strategy = \"steps\"\n",
    "    logging_strategy = \"steps\"\n",
    "    # eval_steps=0.5\n",
    "    per_device_train_batch_size = 24\n",
    "    per_device_eval_batch_size = 8\n",
    "    learning_rate = 2e-5\n",
    "    gradient_accumulation_steps = 8\n",
    "    gradient_checkpointing = True\n",
    "    weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6593ab-eb2e-40ac-b46c-9f90b680cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b018626-37c4-451d-becd-113f394c8a56",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d123710-c14d-4357-a775-dd16ba502708",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(cnfg.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2feb1-5f89-4b8d-b854-f296ee7a7bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 446964\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 55871\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 55870\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb312aa-3a92-4e54-985b-2de0198e679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset[\"train\"]\n",
    "dataset_val = dataset[\"valid\"]\n",
    "dataset_test = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85fbfb-e7d8-45c8-9fce-64a4da991029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446964, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603c53b-a22c-4dc8-9e87-097d8d1ad375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05dad1e1-8d2a-405b-a140-71ea46d6c323",
   "metadata": {},
   "source": [
    "## Get Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ccfb2-74df-4fdf-8e9a-0b7099d2358a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd0eaa-0066-4b44-b48c-97c8f3706aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cnfg.model_name, padding_side=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c893681-9f0a-4d11-9672-655b66b4bb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57a2ee-e3f3-4294-a6c9-ba30526d6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b8268-3cc9-4a51-959f-364a752f9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53944afb-78ce-48a5-aa5d-053c4e545e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4066fc7b-4152-4240-a67f-d6cf9038c586",
   "metadata": {},
   "source": [
    "## Dataloader and Prompt Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5c2d5-6be7-4650-84e4-9fb31d24a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_promt(row):\n",
    "    rslt = f\"{row['input']} \\n ### Instruction:\\n Predict the selling price of car as a non-negative number.\\n ### Response:\\n{row['output']}\"\n",
    "    return rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085414e-591c-43de-85e3-79e0ba99f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    dataset_train,\n",
    "    formatting_func=create_promt,\n",
    "    seq_length=cnfg.sequence_length,\n",
    "    # infinite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b81ce-2d49-4fef-9532-212bd3eba712",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    dataset_val,\n",
    "    formatting_func=create_promt,\n",
    "    seq_length=cnfg.sequence_length,\n",
    "    # infinite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fceee-c803-495b-b7af-3ed5ab9c06da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9548217c-74d3-4051-a927-bea13ee9af6a",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2bfd5a-8276-4367-a49e-8d8445f0943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb87ed82-39af-4235-b4c0-974c19075c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=cnfg.load_in_4bit,\n",
    "    bnb_4bit_quant_type=cnfg.bnb_4bit_quant_type,\n",
    "    bnb_4bit_use_double_quant=cnfg.bnb_4bit_use_double_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec8eb3-117b-4194-8f90-5d0eaf3864ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    cnfg.model_name, quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b313a0-ad92-410c-8547-9a7e794a8f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 257889280 || all params: 1526666240 || trainable%: 16.89231563802708\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73981b8-990b-4a6e-9645-ea504df0cfe0",
   "metadata": {},
   "source": [
    "## Define Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5717c-bc02-4256-b8f1-884303d13673",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=cnfg.r,  # the rank of the LoRA matrices\n",
    "    lora_alpha=cnfg.lora_alpha,  # the weight\n",
    "    lora_dropout=cnfg.lora_dropout,  # dropout to add to the LoRA layers\n",
    "    bias=\"none\",  # add bias to the nn.Linear layers?\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "    ],  # the name of the layers to add LoRA\n",
    "    modules_to_save=None,  # layers to unfreeze and train from the original pre-trained model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b66563-4729-4ab0-9329-35835a127dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=cnfg.output_dir,\n",
    "    evaluation_strategy=cnfg.evaluation_strategy,\n",
    "    max_steps=cnfg.max_steps,\n",
    "    save_steps=100,\n",
    "    logging_steps=100,\n",
    "    eval_steps=100,\n",
    "    # num_train_epochs=cnfg.num_train_epochs,\n",
    "    save_strategy=cnfg.save_strategy,\n",
    "    logging_strategy=cnfg.logging_strategy,\n",
    "    per_device_train_batch_size=cnfg.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=cnfg.per_device_eval_batch_size,\n",
    "    learning_rate=cnfg.learning_rate,\n",
    "    gradient_accumulation_steps=cnfg.gradient_accumulation_steps,\n",
    "    gradient_checkpointing=cnfg.gradient_checkpointing,\n",
    "    weight_decay=cnfg.weight_decay,\n",
    "    run_name=cnfg.run_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea998fe9-b102-4045-985d-8a81f3f734e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:342: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    peft_config=lora_config,\n",
    "    packing=True,\n",
    "    max_seq_length=cnfg.sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e42ab-3f2c-4ad7-86a2-3210a4d22682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83a7f6-26dc-4f58-9ba5-11fb6ec9a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='401' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 401/1000 12:31:58 < 18:48:53, 0.01 it/s, Epoch 0.17/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.501855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.464300</td>\n",
       "      <td>0.443319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>0.428591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='6984' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 120/6984 02:47 < 2:41:29, 0.71 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef45887-13e9-4e4e-afc2-8cc59311324f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
